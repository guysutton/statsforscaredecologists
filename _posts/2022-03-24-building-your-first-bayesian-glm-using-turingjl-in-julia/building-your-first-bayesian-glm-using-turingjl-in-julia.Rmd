---
title: "Fitting your first Bayesian GLM in Julia"
description: |
  Use Turing.jl to fit Bayesian regressions
author:
  - name: Guy F. Sutton
    url: https://twitter.com/stats_ecology
base_url: https://statsforscaredecologists.netlify.app/
preview: plot_preview.png
date: 2022-03-24
output:
  distill::distill_article:
    self_contained: false
    toc: true
draft: false
categories:
  - Julia
  - GLM
  - Bayesian
  - Turing
  - Turing.jl
  - Model fitting 
---

```{r setup, eval=FALSE, echo = F}
knitr::opts_chunk$set(echo = FALSE)

# Setup Julia
library(JuliaCall)
#setup <- julia_setup()
```

# Background 

In earlier posts, I have demonstrated how to fit and interpret the output of simple Gaussian GLM's using both [R](https://statsforscaredecologists.netlify.app/posts/2021-08-04-gaussian-general-linear-model-glm/) and [Julia](https://statsforscaredecologists.netlify.app/posts/2021-08-11-gaussian-glm-in-julia/). However, the field of ecology (and other fields, e.g. economics, health sciences) all seem to be shifting their focus and attention to Bayesian data analysis (BDA), over the traditional frequentest approaches (e.g. null-hypothesis significance testing). I encourage anyone who is interested in the long-standing debate of using frequentist vs bayesian methods to consult people more knowledgeable than me (e.g. [here](https://storopoli.io/Bayesian-Julia/), [here](https://towardsdatascience.com/introduction-to-bayesian-linear-regression-e66e60791ea7), and [here](https://www.sciencedirect.com/book/9780128013700/bayesian-data-analysis-in-ecology-using-linear-models-with-r-bugs-and-stan)).

Very simply, Bayesian methods differ from traditional frequentist methods [in two primary ways](https://towardsdatascience.com/introduction-to-bayesian-linear-regression-e66e60791ea7):  

- *Priors*: Frequentist approaches assume that all of the information we can derive must come from the underlying data (e.g. model parameters). Bayesian methods allow us to incorporate other information (e.g. literature), or an uninformed guess, about what the model parameters could be, called a *prior*. Where we don't have any information, we can fall back into *non-informative priors*, such as the normal (Gaussian) distribution.   

- *Posterior*: A Bayesian approach allows us to calculate a distribution of possible models parameters based on the actual data and the prior information we have. Because we are calculating a distribution of model parameters, we can also quantify uncertainty around these estimates. This allows us to make probabilistic statements such as: given the model we fit, the data and the prior information we have about the topic, there is an Z% chance that the effect of covariate X increases Y by so much... This is a bit wordy, but it will hopefully be more clear with an example.      

My potentially oversimplified summary of Bayesian vs frequentist approaches is that Bayesian methods aim to generate a probability distribution of possible model paramters, while frequentist methods are geared towards trying to estimate a single `best estimate` of the model parameters. 

In today's blogpost, I want to demonstrate the basics of fitting, evaluating and interpreting a simple Bayesian linear regression in `Julia`. I am by no means an expert in Bayesian analysis, so if any experts are reading this and have any pointers, please let me know. This post will be purposely kept as simple as possible to serve as a light and breezy introduction to an otherwise challenging and complex statistical modelling toolbox. 

* Please note, there is an apparent dependency issue with installing `TuringGLM.jl` in `R` that doesn't seem to have an easy fix (at least not for me), which I use to write and host my blogposts. As such, I will be showing some screenshots of the required output when I run the analysis in `Julia`. 

# Load required packages 

To fit a Bayesian regression model in `Julia`, we are going to take advantage of the amazing `Turing.jl` package in Julia. `Turing.jl` is a general-purpose probabilistic programming package that allows `Julia` users to fit Bayesian models using standard `Julia syntax`. For more details, please consult the [`Turing.jl` homepage](https://github.com/TuringLang/Turing.jl). In fact, we are actually going to use another package, [`TuringGLM.jl`](https://github.com/TuringLang/TuringGLM.jl) to specify our models using simple coding syntax, and it will return an instantiated `Turing` model without us having to lift a finger, so to speak. The syntax of `Turing.jl` is very similar to using `brms` in `R` (insert ref), which makes the transition between languages easy. 

```{julia load_packages, echo = TRUE}
# Load the package manager
using Pkg

# # Install required packages (once-off)
# Pkg.add("GLM")             # General linear models (GLM)
# Pkg.add("StatsModels")     # Perform likelihood-ratio test
# Pkg.add("DataFrames")      # Manipulating data structures (Julia's version of 'dplyr')
# Pkg.add("StatsBase")       # Basic statistical functions (e.g. mean, stddev)
# Pkg.add("Statistics")      # More basic statistical functions 
# Pkg.add("Distributions")   # Fit basic statistical distributions 
# Pkg.add("Plots")           # Plot figures 
# Pkg.add("StatsPlots")      # Grouped box-plots recipe
# Pkg.add("Turing")          # Dependency for probabilistic probability calculations 
# Pkg.add("TuringGLM")       # Bayesian GLM's

# # Load required packages (every new session)
using GLM                    # General linear models (GLM)
using StatsModels            # Perform likelihood-ratio test
using DataFrames             # Manipulating data structures (Julia's version of 'dplyr')
using StatsBase              # Basic statistical functions (e.g. mean, stddev)
using Statistics             # More basic statistical functions 
using Distributions          # Fit basic statistical distributions 
using Plots                  # Plot figures 
using StatsPlots             # Grouped box-plots recipe
using Turing                 # Dependency for probabilistic probability calculations 
# using TuringGLM              # Fit Bayesian GLM's 
using RCall                  # Port the 'Salamanders' dataset from R's 'glmmTMB' package 
```

# Load data 

Let's read in the `salamanders` dataset that is built-in to the `glmmTMB` package in `R` (insert ref). The `salamanders` dataset consists of counts (abundances) of a number of different salamander species from 23 different sites. There are a number of site (e.g. the amount of cover objects in the stream `cover`) and sampling covariates in the dataset (e.g. the day of the year each sampling event occurred `DOY`). Each site was sampled on 4 separate occasions, meaning that there is a hierarchical structure in the data, however, let's not worry about that for today (we will come back to this in a later blogpost). 

```{julia, echo = TRUE}
# Load in the dataset 
salamanders = RCall.rcopy(R"glmmTMB::Salamanders")
```

# Fitting a model 

As I briefly mentioned above, we can take advantage of the [`TuringGLM.jl`](https://github.com/TuringLang/TuringGLM.jl) package to specify our model. `TuringGLM.jl` uses a simple coding syntax, that is consistent with other `Julia` packages such as `StatsModels.jl` and `MixedModels.jl`, and it will return an instantiated `Turing.jl` model without us having to do too much work.

Let's say that we want to model water temperature (`Wtemp`) as a function of how much of the stream area is covered by objects (e.g. rocks, woody debris) (`cover`) and the day of the year that sampling took place (`DOY`). This was not the intent of the original study - I am using this as a case-study example only. We are not interested in the actual results here, rather, pay attention to the process and familiarizing yourself with the code and how to interpret the model fits.   

### Step 1: Specify the model 

There are two components to specifying a Bayesian model. The first component is the *likelihood*, which is basically the same as selecting which family to pick using a standard GLM (e.g. Gaussian, Poisson, ect...). The second component is specifying the *priors* (e.g. prior information from the literature or a pilot study), if we have any.  

The model is specified using using the @formula macro and then specifying the dependent variable followed by a tilde ~ then the independent variables separated by a plus sign +, or * if an interaction term is required.   

```{julia fit_glm, eval = F, echo = T} 
# Step #1: Specify the model formula
# - Response variable: Wtemp (water temperature)
# - Predictor variable(s): cover (vegetation cover) + DOY (day of year)
fm = @formula(Wtemp ~ cover + DOY)

# Step 2: Fit the model 
# - The first argument is the formula object we specified above 
# - The second argument is the dataset containing the response and predictor variables
# - Because we are specifying a linear regression, we do not need to specify any 
#   likelihood distribution (e.g. Poisson, Bernoulli, ect...)
model = TuringGLM.turing_model(fm, salamanders)
```

Notice that we haven't given the model any information other than the raw data. In other words, we have not specified any *priors*. When this happens, *TuringGLM.jl* will take care of us, and specify what it calls ["...state-of-the-art default priors, based on the literature and the Stan community..."](https://github.com/TuringLang/TuringGLM.jl/blob/main/src/turing_model.jl).  

### Step 2: Sampling the posterior  

The next step is to draw samples from the posterior distribution. This allows us to calculate a distribution for each of the model parameters given the underlying data. The way we do this is to use the `sample` function from `Turing.jl`. There is a lot of fancy stuff going on in the background to draw the samples. You can take a look [here](https://storopoli.io/Bayesian-Julia/pages/5_MCMC/) if you want to dive into the nitty-gritty. 

For today, we are going to keep it simple and use the default method, the `No U-turn sampler`, otherwise known as `NUTS`, to sample the posterior. 

```{julia sample_posterior, eval = F, echo = T}
# Extract parameter estimates using `sample` from 'Turing.jl'
# - Use No U-Turn Sampleer (NUTS) with 2000 samples 
# - Sample from 4 Markov chains using multiple threads MCMCThreads()
n_samples = 2000
results = Turing.sample(model, Turing.NUTS(), MCMCThreads(), n_samples, 4)
```

### Step 3: Evaluate the model fit 

The next step is to perform some checks that the model fit was okay. This is roughly equivalent to performing residual diagnostics in a frequentist modelling framework (e.g. QQplots, fitted vs residual plots, ect...). There are two essential checks we must perform:

- (1) [*Trace plots*](https://storopoli.io/Bayesian-Julia/pages/5_MCMC/): These plots show us how well our model has converged on its parameter estimates. What we want to see is the parameter estimates remaining stable (i.e. no patterns or obvious slopes) across the range of posterior samples and the draws from each train to be well mixed.  
- (2) [*R-hat*](https://storopoli.io/Bayesian-Julia/pages/5_MCMC/): This value is a numerical estimate of whether the chains we have inspected in the traceplots have converged or not. *R-hat* must be above 0.99 and below 1.01 for our model to be considered valid (Brooks & Gelman, 1998; Gelman & Rubin, 1992). 

Let's take a look at our trace plots using the built-in `traceplot` function in `MCMCChains.jl`:  

```{julia trace_plots, eval = F, echo = T}
MCMCChains.traceplot(results, legend = :outerright)
```

```{r import_traceplots, echo = FALSE, out.width = "100%"}
knitr::include_graphics("fig_traceplots.png", dpi = NA)
```

Inspecting the plots indicates that the chains are well mixed (i.e. all the different coloured squiggly lines are plotted over one another) and that the chains have converged on a certain range for each model parameter (i.e. the range of the y-axis spread is relatively consistent across the range of the x-axis). Happy days. 

Now let's calculate *R-hat*:   

```{r rhat, eval = F, echo = T}
StatsBase.summarystats(results)
```

```{r import_rhat, echo = FALSE, out.width = "100%"}
knitr::include_graphics("output_rhat.png", dpi = NA)
```

All our *R-hat* values for the different model parameters fall within the bounds of 0.99 and 1.01. Thank goodness. We can be quite happy that our model appears to have converged and the parameter estimates that we obtain appear to be stable. 

### Step 4: Model inference 

The last step is to perform model inference. To do this, we can calculate summary statistics from the posterior distributions of the different model parameters. 

The first thing to do here is to plot the posterior distributions of the different model parameters.   

```{julia posteriors, eval = F, echo = T}
StatsPlots.plot(results, seriestype = :mixeddensity)
```

```{r import_posteriors, echo = FALSE, out.width = "100%"}
knitr::include_graphics("fig_posteriors.png", dpi = NA)
```

The two plots that we are interested in are the ones labelled `B[1]` (which is the slope of the first X covariate we specified in the model formula, namely: $\beta$~[cover]~) and `B[2]` (which represents the slope for the second X covariate we specified in the model formula, namely: $\beta$~[DOY]~). The posterior distribution for `B[1]` is centered around -0.16, and ranges between -0.04 and about 0.30. Roughly, this implies that the average change in water temperature associated with a one unit change in `cover` is a decrease of 0.15 degrees. Similarly, the posterior distribution for `B[2]` is centered around 0.08, and ranges between -0.03 and about 0.3. Roughly, this implies that the average change in water temperature associated with a one unit change in `DOY` is a increase of about 0.08 degrees. 

We can calculate some more informative summary statistics that will allow us to summarise and interpret our results more succinctly. To do this, we can calculate *credible intervals*. These are basically what most ecologists interpet as *confidence intervals* using a frequentist modelling approach. There is an important distinction between the two definitions, however. For example, a 95% *confidence interval* tells us that if the experiment were repeated 100 times, we would reasonably expect the best parameter estimate to fall within the bounds of the confidence interval calculated 95% of times. This is not the same as a *credible interval*, which allows us to make a probabilistic statement about the treatment effect, as discussed above. Let's illustrate with our example.   

```{julia credible_intervals, eval = F, echo = T}
# Calculate parameter estimates and credible intervals 
# - Read the 95% CI as the 97.5 - 2.5% columns 
Statistics.quantile(results)
```

```{r import_credible_intervals, echo = FALSE, out.width = "100%"}
knitr::include_graphics("output_cred_intervals.png", dpi = NA)
```

The 95% *credible interval* for $\beta$~[cover]~ is -0.08 to -0.23. This means that there is a 95% chance that the change in water temperature associated with a one unit increase in cover is somewhere between a 0.08 to 0.23 degree decrease. Note that we know the effect is a decrease because of the negative sign of the parameter estimates and intervals. Also note, at no point have we ever calculated a p-value. We can infer that the `cover` variable was statistically significant, whatever that means, because the *credible interval* for $\beta$~[cover]~ did not include 0 (which would indicate no effect on water temperature). 

Similarly, the 95% *credible interval* for $\beta$~[DOY]~ is 0.0003 to 0.14. This means that there is a 95% chance that the change in water temperature associated with a one unit increase in `DOY` is somewhere between a 0.0004 to 0.14 degree increase.

# Compare with frequentist approach

Let's now compare the Bayesian linear regression model we fitted above with an ordinary least squares (OLS) model. 

```{julia ols}
ols = lm(@formula(Wtemp ~ cover + DOY), salamanders)
```

As we touched on above, the estimates obtained from OLS indicate a single best estimate of the covariates effect on Y. We can see here that the $\beta$~[cover]~ = -0.15, with a 95% confidence interval of -0.08 to -0.23. These estimates are basically identical to the Bayesian estimates derived above ($\beta$~[cover]~ = -0.15, with a 95% credible interval of -0.08 to -0.23). Given that we didn't provide any *priors* to our Bayesian model, this isn't a huge surprise. 

# Conclusion

Let's leave it there for today. Bayesian data analysis is not easy, particularly for people like me who have been using frequentist modelling approaches for so long. However, I hope that today you have seen the power of using Bayesian models in your research. The real joy of this approach is the probabalistic statements that we can make when performing model inference and not relying on a binary p-value to assess statistical significance, but rather, we focus on estimating the magnitude of the effect. In later posts, we will cover more advanced Bayesian modelling strategies, including how to plot predictions from the model. Any feedback would be much appreciated. 











































































































